# Testing Lallama 7B Models for general GEN AI


## Two point aproach

 - [] Master prompt template without fine tuning
 - [] Fine tuning with with limited data tests
    - in poggers


## Compare perfs, quants and check lower models


## Local setup

- 64 GB ram 6 ghz
- 16 GB VRAM - cuda available
- WSL 2
- Ollama
- Hugging face
- python
    - for llm communication
    - data generation
    - data extraction TBD
- TODO :/ create requqiments.txt
- TBD://Copy paste instructions that work


# TODO
 - Understand slop
 - TYPOS
 - short prompts [village,weather,3 words max]
 - API
 - Client
 - Maintainece of requqiments.txt
