# Testing Lallama 7B Models for general GEN AI


## Two point aproach 

 - [] Master prompt template without fine tuning
 - [] Fine tuning with with limited data tests


## Compare perfs


## Local setup

- 64 GB ram 6 ghz
- 16 GB VRAM - cuda available
- WSL 2 
- Ollama
- Hugging face
- python
    - for llm communication
    - data generation
    - data extraction TBD
- TODO :/ create requqiments.txt
- TBD://Copy paste instructions that work
